# Parameter Optimization of SVM


Support Vector Machine (SVM) is a widely used supervised learning algorithm that can accurately classify and analyze regression data. SVM is highly effective in finding the best boundary that divides the data points into their respective classes by creating a hyperplane in a high-dimensional space.

To achieve optimal performance from SVM, it is essential to carefully select various parameters like the kernel type, regularization parameter, and the kernel coefficient. These parameters significantly impact the performance of the SVM model, and their optimal values can be determined by a process called parameter optimization.

Parameter optimization is the process of systematically searching through the parameter space to identify the best combination of parameter values that maximizes the performance of the SVM model on a given dataset. There are several methods for parameter optimization, including grid search, random search, and Bayesian optimization. These methods help in finding the best set of parameter values that improve the accuracy of the SVM model on the test data.


## Tasks Performed
1. Download the dataset
2. Pre-process the dataset
3. Create ten samples 
4. Split the samples in  70 : 30 for training and testing
5. Optimise SVM using randomisation for every sample and report best accuracy and best parameters
6. For the best sample plot the convergence graph

## Parameters Optimized

The following parameters are optimized in this project:

- **nu:** the parameter that controls the number of support vectors used in the model.
- **kernel:** the kernel function used for the SVM algorithm.
- **epsilon:** the margin of error allowed in the SVM algorithm.

## Convergence Graph
<img width="733" alt="Screenshot 2023-04-20 at 1 06 21 AM" src="https://user-images.githubusercontent.com/72341235/233181801-f0396852-629e-40ca-abf0-207c3c1daca3.png">


## Submission by :
*Name* : Agamjot Singh
<br>
*Roll No* : 102016068
<br>
*Batch* : CS 11






## Result 


#


